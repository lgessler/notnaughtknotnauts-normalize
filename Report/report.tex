%
% File naacl2019.tex
%
%% Based on the style files for ACL 2018 and NAACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage{authblk}
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Orthographic Normalization of Historical Texts}

\author{Pryce Bevan}
\author{Luke Gessler}
\author{Michael Kranzlein}
\affil{Georgetown University\\ Department of Computer Science}
\affil{\{\tt pwb8, lg876, mmk119\}@georgetown.edu}

\date{}

\begin{document}
\maketitle

\begin{abstract}
We explore several model architectures for token-based historical text normalization. At the token level, we observe that a na\"ive baseline imposes an upper bound on model performance on tokens seen in training data. Accordingly, we implement an LSTM model and a transformer model to predict unseen tokens and incorporate the baseline's predictions for seen tokens. We test these hybrid models on historical Spanish texts and achieve results that are on par with state-of-the-art models. We also note that TODO outperforms TODO.
\end{abstract}

\section{Introduction}
In many cases, researchers require or prefer to work with standardized data. In this work, we examine historical text normalization---``the problem of translating historical documents written in the absence of modern spelling conventions and making them amenable to search by today’s scholars, processable by natural language processing models, and readable to laypeople" \cite{bollmann_multi-task_2018}. This is a standardization problem that...

\subsection{Motivating the Normalization Problem}
% TODO: Cite Amir's stuff on Coptic normalization:
% https://www.aclweb.org/anthology/W16-2119
% http://copticscriptorium.org/FAQ.html

\section{Related Work}
Historical text normalization has received renewed attention as neural approaches have gained traction in the NLP community. Over the past ten years, the state of the art has seen an evolution from Hidden Markov Models and rule-based models to simple neural networks to more context-aware recurrent neural networks. Most recently, there is a shift toward attention and transformers.
\subsection{HMM and Rule-Based Methods}
\subsection{Neural Networks}
\subsection{Recurrent Neural Networks}
\subsection {Attention and Transformers}

\section{Model}
\subsection{Dataset}
For this research, we make use of the Post Scriptum corpus, a resource built in 2014 to promote work in the digital humanities \cite{vaamonde_post_2014}. The corpus contains epistolary texts in Spanish and Portuguese, ranging from the 16th century to the 19th century. These documents are unpublished and  represent a diverse set of social backgrounds. For our experiments, we use only the Spanish texts, totaling 2368 documents. Each original document is accompanied by a corresponding manually modernized document. Our models ingest an original token as input and predict the best modern equivalent.
\subsubsection{Example}
% TODO: Fix figure formatting
\begin{figure}[h]
\begin{quotation}
\noindent \textit{por me hazer md me ebye el bonete q conpre aqui}
\caption{Test}
\end{quotation}
\end{figure}
\begin{figure}[h]
\begin{quote}
\textit{Por me hacer merced, me envíe el bonete que compré aquí.}
\caption{Modernized}
\end{quote}
\end{figure}
\subsection{Na\"ive Baseline}
\subsection{LSTM Model}
\subsection{Transformer Model}

\section{Results}
% TODO: Fix table headings
\begin{center}
	\begin{tabular}{ c c c c c  c}
		Char & Char & Char & Word & Word & Word\\
		\hline
		1 & 1 & 1 & 1 & 1 & 1
	\end{tabular}
\end{center}

%TODO: Add character-differential accuracy table
\section{Analysis}

\section{Conclusion}

\section*{Acknowledgments}

\bibliography{report}
\bibliographystyle{acl_natbib}

\end{document}
